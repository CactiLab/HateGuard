{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose sequence as a NLI premise and label as a hypothesis\n",
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load model pretrained on MNLI\n",
    "from transformers import BartForSequenceClassification, BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "sent_model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli').to(device)\n",
    "\n",
    "# add special tokens\n",
    "tokens = ['chinavirus', 'cherry picker', 'china virus','coronaviruschina', 'ccpvirus', 'covididot'\n",
    "          'kungflu','chinese virus','wuhanvirus', 'wuhan virus', 'maskless', 'womensuch', 'walkaway',\n",
    "          'antimask','antivaccine', 'novaccine',  'antivax', 'unvaccinated', 'maskoff', 'boomer', \n",
    "          'maskfree', 'babyboomer', 'boomerremover', 'boomer remover', 'wuflu', 'fuckchina', 'NaziRussia', 'SanctionRussiaNow', 'MAGARioters',\n",
    "          'LockThemUp', 'MAGAMorons', 'Magaidiots']\n",
    "          \n",
    "tokenizer.add_tokens(tokens, special_tokens=True)\n",
    "sent_model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\" \") # path to the data\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 100 of each category to form a training set\n",
    "df_train = df.groupby('category').apply(lambda x: x.sample(n=100, random_state=1)).reset_index(drop=True)\n",
    "# the rest data as test set\n",
    "df_test = df[~df.index.isin(df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 3400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [00:00, 2161.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare the training pairs\n",
    "train = []\n",
    "\n",
    "for index, row in tqdm(df_train.iterrows()):\n",
    "    sentence = row['text']\n",
    "    label = row['ground_truth']\n",
    "    entailment = 'It is hate speech'\n",
    "    contradiction = 'It is normal speech'\n",
    "    pos_tokens = tokenizer.encode(sentence, entailment, max_length=256, truncation=True, return_tensors='pt').to(device)\n",
    "    neg_tokens = tokenizer.encode(sentence, contradiction, max_length=256, truncation=True, return_tensors='pt').to(device)\n",
    "    tokens = torch.stack((pos_tokens[0], neg_tokens[0]), dim=0)\n",
    "    train.append((tokens, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(sent_model.parameters(), lr=0.001, momentum=0.9)\n",
    "crossentropy = torch.nn.CrossEntropyLoss().to(device)\n",
    "labels = ['hate', 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train_model(model, dataset, num_epoch=100):\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        # print('epoch', epoch)\n",
    "        loss_epoch = 0\n",
    "        for posneg, label in tqdm(dataset):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(posneg)[0]\n",
    "            posneg_output = output[:, [0, 2]]\n",
    "            probs = posneg_output.softmax(dim=1)\n",
    "            if label == 1.0:\n",
    "                y = torch.LongTensor([1, 0]).to(device)\n",
    "            else:\n",
    "                y = torch.LongTensor([0, 1]).to(device)\n",
    "            loss = crossentropy(probs, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss.item()\n",
    "        loss = loss_epoch / len(dataset)        \n",
    "        print('epoch', epoch, 'loss', loss)\n",
    "    \n",
    "        # return the best model\n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a prediction function\n",
    "def predict_normal(tokenizer, model, sentence, labels):\n",
    "  predit = {}\n",
    "\n",
    "  premise = sentence\n",
    "  for label in labels:\n",
    "    # base \n",
    "    hypothesis = f'It is {label} speech.'\n",
    "    # meta\n",
    "    # hypothesis = f'This tweet contains {label} speech'\n",
    "    input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt').to(device)\n",
    "    logits = model(input_ids)[0]\n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    true_prob = probs[:,1].item() \n",
    "    predit[label] = true_prob\n",
    "  return predit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(dataframe):\n",
    "    for cate in dataframe.category.unique().tolist():\n",
    "        df_sub = dataframe[dataframe['category']==cate]\n",
    "        print(cate)\n",
    "        print(classification_report(df_sub['label'], df_sub['prediction'], digits=3))\n",
    "        print('====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      " Begin training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:25<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.7062429959575335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:21<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.6960038682818412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:14<00:00,  1.38it/s]\n",
      " 30%|███       | 3/10 [22:02<51:16, 439.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 0.6967804491519928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:13<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.692230008840561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:16<00:00,  1.37it/s]\n",
      " 50%|█████     | 5/10 [36:33<36:25, 437.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 0.6969385200738907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:11<00:00,  1.39it/s]\n",
      " 60%|██████    | 6/10 [43:45<29:01, 435.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 loss 0.6953397971391678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:15<00:00,  1.38it/s]\n",
      " 70%|███████   | 7/10 [51:00<21:46, 435.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss 0.6957552050550778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:18<00:00,  1.37it/s]\n",
      " 80%|████████  | 8/10 [58:19<14:32, 436.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 loss 0.6952378838260969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:06<00:00,  1.41it/s]\n",
      " 90%|█████████ | 9/10 [1:05:26<07:13, 433.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 loss 0.6940576441089312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:16<00:00,  1.38it/s]\n",
      "100%|██████████| 10/10 [1:12:42<00:00, 436.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss 0.6937162359555562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "sent_model.train()\n",
    "print('=====================\\n Begin training:')\n",
    "model = train_model(sent_model, train, 10)\n",
    "# torch.save(model.state_dict(), 'fsl_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of the meta-learner on the EFL dataset\n",
    "# define a prediction function\n",
    "def predict_normal(tokenizer, model, sentence, labels):\n",
    "  predit = {}\n",
    "\n",
    "  premise = sentence\n",
    "  for label in labels:\n",
    "    # base \n",
    "    hypothesis = f'It is {label} speech.'\n",
    "    # meta\n",
    "    # hypothesis = f'This tweet contains {label} speech'\n",
    "    input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt').to(device)\n",
    "    logits = model(input_ids)[0]\n",
    "    entail_contradiction_logits = logits[:,[0,2]]\n",
    "    probs = entail_contradiction_logits.softmax(dim=1)\n",
    "    true_prob = probs[:,1].item() \n",
    "    predit[label] = true_prob\n",
    "  return predit\n",
    "\n",
    "def comparison(prediction, label):\n",
    "  tp = 0\n",
    "  fp = 0\n",
    "  tn = 0\n",
    "  fn = 0\n",
    "\n",
    "  # get the prediction label\n",
    "  pred = max(prediction, key=prediction.get)\n",
    "  if pred == 'hate':\n",
    "    pred_label = 1\n",
    "  else:\n",
    "    pred_label = 0\n",
    "  # print(pred, d['label'])\n",
    "  # calculate the tp, fp, tn, fn values\n",
    "  if pred_label == label:\n",
    "    if label == 1:\n",
    "      tp += 1\n",
    "    else:\n",
    "      tn += 1\n",
    "  else:\n",
    "    if label == 1:\n",
    "      fn += 1\n",
    "    else:\n",
    "      fp += 1\n",
    "  \n",
    "  return tp, fp, tn, fn\n",
    "\n",
    "def get_report(tp, fp, tn, fn):\n",
    "  accuracy = (tp + tn) / (tp+fp+tn+fn)\n",
    "  precision = tp / (tp + fp)\n",
    "  recall = tp / (tp + fn)\n",
    "  f1 = (precision*recall) /(precision+recall) * 2\n",
    "  report = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "  return report\n",
    "labels = ['hate', 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832/832 [04:26<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 185 202 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4963942307692308,\n",
       " 'precision': 0.5328282828282829,\n",
       " 'recall': 0.47415730337078654,\n",
       " 'f1': 0.5017835909631391}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for Asian Hate\n",
    "results = [0,0,0,0]\n",
    "# random.shuffle(df_test[df_test['category']=='asian'])\n",
    "for index, row in tqdm(df_test[df_test['category']=='asian'].iterrows(), total=df_test[df_test['category']=='asian'].shape[0]):\n",
    "  # print(d['tweet'])\n",
    "  text = str(row['text'])\n",
    "  predictions = predict_normal(tokenizer, model, text, labels)\n",
    "  distribution = comparison(predictions, row['ground_truth'])\n",
    "  for index, integer in enumerate(distribution):\n",
    "    results[index] += integer\n",
    "\n",
    "tp, fp, tn, fn = results\n",
    "print(tp, fp, tn, fn)\n",
    "get_report(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [01:57<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 121 109 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4903581267217631,\n",
       " 'precision': 0.3631578947368421,\n",
       " 'recall': 0.518796992481203,\n",
       " 'f1': 0.42724458204334365}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for Ageism Hate\n",
    "results2 = [0,0,0,0]\n",
    "for index, row in tqdm(df_test[df_test['category']=='ageism'].iterrows(), total=df_test[df_test['category']=='ageism'].shape[0]):\n",
    "    text = str(row['text'])\n",
    "    predictions = predict_normal(tokenizer, model, text, labels)\n",
    "    distribution = comparison(predictions, row['ground_truth'])\n",
    "    for index, integer in enumerate(distribution):\n",
    "        results2[index] += integer\n",
    "\n",
    "tp, fp, tn, fn = results2\n",
    "print(tp, fp, tn, fn)\n",
    "get_report(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:43<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 161 164 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4949698189134809,\n",
       " 'precision': 0.3374485596707819,\n",
       " 'recall': 0.47674418604651164,\n",
       " 'f1': 0.3951807228915663}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for Mask Hate\n",
    "results3 = [0,0,0,0]\n",
    "for index, row in tqdm(df_test[df_test['category']=='mask'].iterrows(), total=df_test[df_test['category']=='mask'].shape[0]):\n",
    "    text = str(row['text'])\n",
    "    predictions = predict_normal(tokenizer, model, text, labels)\n",
    "    distribution = comparison(predictions, row['ground_truth'])\n",
    "    for index, integer in enumerate(distribution):\n",
    "        results3[index] += integer\n",
    "\n",
    "tp, fp, tn, fn = results3\n",
    "print(tp, fp, tn, fn)\n",
    "get_report(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 404/497 [02:13<00:30,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 128 129 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.49504950495049505,\n",
       " 'precision': 0.35678391959798994,\n",
       " 'recall': 0.48299319727891155,\n",
       " 'f1': 0.4104046242774566}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for Vaccine Hate\n",
    "results4 = [0,0,0,0]\n",
    "for index, row in tqdm(df_test[df_test['category']=='vaccine'].iterrows(), total=df_test[df_test['category']=='mask'].shape[0]):\n",
    "    text = str(row['text'])\n",
    "    predictions = predict_normal(tokenizer, model, text, labels)\n",
    "    distribution = comparison(predictions, row['ground_truth'])\n",
    "    for index, integer in enumerate(distribution):\n",
    "        results4[index] += integer\n",
    "\n",
    "tp, fp, tn, fn = results4\n",
    "print(tp, fp, tn, fn)\n",
    "get_report(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [03:48<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 184 206 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5411931818181818,\n",
       " 'precision': 0.48746518105849584,\n",
       " 'recall': 0.5573248407643312,\n",
       " 'f1': 0.5200594353640416}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for us_capitol Hate\n",
    "results5 = [0,0,0,0]\n",
    "for index, row in tqdm(df_test[df_test['category']=='us_capitol'].iterrows(), total=df_test[df_test['category']=='us_capitol'].shape[0]):\n",
    "    text = str(row['text'])\n",
    "    predictions = predict_normal(tokenizer, model, text, labels)\n",
    "    distribution = comparison(predictions, row['ground_truth'])\n",
    "    for index, integer in enumerate(distribution):\n",
    "        results5[index] += integer\n",
    "\n",
    "tp, fp, tn, fn = results5\n",
    "print(tp, fp, tn, fn)\n",
    "get_report(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [03:31<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 186 177 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4866666666666667,\n",
       " 'precision': 0.38205980066445183,\n",
       " 'recall': 0.48523206751054854,\n",
       " 'f1': 0.42750929368029744}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for rus_ukr Hate\n",
    "results6 = [0,0,0,0]\n",
    "for index, row in tqdm(df_test[df_test['category']=='rus_ukr'].iterrows(), total=df_test[df_test['category']=='rus_ukr'].shape[0]):\n",
    "    text = str(row['text'])\n",
    "    predictions = predict_normal(tokenizer, model, text, labels)\n",
    "    distribution = comparison(predictions, row['ground_truth'])\n",
    "    for index, integer in enumerate(distribution):\n",
    "        results6[index] += integer\n",
    "\n",
    "tp, fp, tn, fn = results6\n",
    "print(tp, fp, tn, fn)\n",
    "get_report(tp, fp, tn, fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
