{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO-1uUWFxGzH"
      },
      "source": [
        "## This code collects potential terms and targets given a set of seed tweets.\n",
        "## We first use KeyBERT to get key terms. Then use dictionaries to filter out known words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5RB161gFoUZ"
      },
      "outputs": [],
      "source": [
        "!pip install keybert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTLWlc7ff6Dt"
      },
      "outputs": [],
      "source": [
        "!pip install pyenchant==3.0.0a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4UFyyjOheqg"
      },
      "outputs": [],
      "source": [
        "!apt-get install enchant-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PNpXdmOCvemY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"<-read the seed dataset->\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vktlCPYOw2Ng",
        "outputId": "f6508345-a0b5-4229-da2e-0ce80e4c319f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "def get_key_terms(text):\n",
        "  keywords = kw_model.extract_keywords(text)\n",
        "  terms = ''\n",
        "  for word, conf in keywords:\n",
        "    if conf > 0.5:\n",
        "      terms = terms + ' ' + word\n",
        "  return terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-vcmGNGRA4vu"
      },
      "outputs": [],
      "source": [
        "# get the data that are hateful\n",
        "data_hate = data[data['ground_truth']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E5cBkMl-ugCA"
      },
      "outputs": [],
      "source": [
        "data_age = data_hate[data_hate['category']=='ageism']\n",
        "data_asian = data_hate[data_hate['category']=='asian']\n",
        "data_vac = data_hate[data_hate['category']=='vaccine']\n",
        "data_mask = data_hate[data_hate['category']=='mask']\n",
        "data_us = data_hate[data_hate['category']=='us_capitol']\n",
        "data_rus = data_hate[data_hate['category']=='rus_ukr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_gaOD23y0PWw"
      },
      "outputs": [],
      "source": [
        "def is_english_word(word):\n",
        "    d = enchant.Dict(\"en_US\")\n",
        "    return d.check(word), d.suggest(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uhS34ukp01Kt"
      },
      "outputs": [],
      "source": [
        "def is_urban_word(word, date_key):\n",
        "    url = f\"https://api.urbandictionary.com/v0/define?term={word}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    if data['list']:\n",
        "        when = data['list'][0]['written_on']\n",
        "\n",
        "        # check if the word is a new term or not\n",
        "        if datetime.strptime(when, \"%Y-%m-%dT%H:%M:%S.%fZ\") < date_key:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "    else:\n",
        "        return True\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Ac_qIn5NAsjc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import enchant\n",
        "\n",
        "def keyword_extract(data, month, year):\n",
        "  # get keywords\n",
        "  terms = set()\n",
        "  for i in range(5):\n",
        "    random_number = random.randint(10, 20)\n",
        "    try:\n",
        "      data_seed = data.sample(n = random_number)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    for date, text, gt in zip(data_seed['month'].tolist(), data_seed['original_text'].tolist(), data_seed['ground_truth'].tolist()):\n",
        "      if date == month:\n",
        "        if gt == 1:\n",
        "          keywords_text = get_key_terms(text)\n",
        "          for word in keywords_text.split():\n",
        "            terms.add(word)\n",
        "  terms = list(terms)\n",
        "  print(\"\\nKeywords found:\\n\", terms)\n",
        "\n",
        "  new_derog_terms = set()\n",
        "  for word in terms:\n",
        "    if word.isnumeric():\n",
        "      continue\n",
        "\n",
        "    cleaned_word = ''.join(letter for letter in word if letter.isalnum())\n",
        "    if cleaned_word != '':\n",
        "      present, suggs = is_english_word(cleaned_word)\n",
        "    else:\n",
        "      present = True\n",
        "    if not present:\n",
        "        new_derog_terms.add(cleaned_word)\n",
        "  new_derog_terms = list(new_derog_terms)\n",
        "  # print(\"\\n\",new_derog_terms)\n",
        "\n",
        "  final_set = set()\n",
        "  for word in new_derog_terms:\n",
        "      if is_urban_word(word, datetime.strptime(f'{year}-{month}-1', '%Y-%m-%d')):\n",
        "          final_set.add(word)\n",
        "  final_terms = list(final_set)\n",
        "  print(\"The final terms are:\", final_set)\n",
        "  return final_terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVSl29zZzti0",
        "outputId": "beafa6a7-4ade-4bd6-dd74-5fbd7031563e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keywords found:\n",
            " ['becky', 'boomers', 'beckydonthavethegoodhairthough']\n",
            "The final terms are: {'beckydonthavethegoodhairthough'}\n",
            "\n",
            "Keywords found:\n",
            " ['ageism', 'boomers']\n",
            "The final terms are: set()\n",
            "\n",
            "Keywords found:\n",
            " ['mustard', 'covididiot']\n",
            "The final terms are: {'covididiot'}\n",
            "\n",
            "Keywords found:\n",
            " ['boomers', 'boomer', 'remover']\n",
            "The final terms are: set()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_extract(data_age, 1, 2020)\n",
        "keyword_extract(data_age, 4, 2020)\n",
        "keyword_extract(data_age, 7, 2020)\n",
        "keyword_extract(data_age, 10, 2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhC0rrj_Zci3",
        "outputId": "137744a8-d8b7-4d1d-c406-29d2c7a92b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keywords found:\n",
            " ['chinese', 'kung', 'fuckchina', 'coronaravirus', 'plague']\n",
            "The final terms are: {'coronaravirus', 'fuckchina'}\n",
            "\n",
            "Keywords found:\n",
            " ['hongkongers', 'unemployed', 'chinesevirus', 'malaysia', 'fuckchina', 'china_is_terrorist', 'hongkong']\n",
            "The final terms are: {'chinesevirus', 'chinaisterrorist', 'fuckchina'}\n",
            "\n",
            "Keywords found:\n",
            " ['chinaliedpeopledied', 'chinavirus', 'chineseappsblocked', 'covid', 'chinagetoutofiran', 'coronavirus', 'pandemic', 'chinafreeworld']\n",
            "The final terms are: {'chinaliedpeopledied', 'chinavirus', 'chineseappsblocked', 'covid', 'chinagetoutofiran', 'chinafreeworld'}\n",
            "\n",
            "Keywords found:\n",
            " ['chinesevirus', 'wuhanvirus', 'chinavirus', 'ccp_is_terrorist']\n",
            "The final terms are: {'chinesevirus', 'wuhanvirus', 'chinavirus', 'ccpisterrorist'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['chinesevirus', 'wuhanvirus', 'chinavirus', 'ccpisterrorist']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_extract(data_asian, 1, 2020)\n",
        "keyword_extract(data_asian, 4, 2020)\n",
        "keyword_extract(data_asian, 7, 2020)\n",
        "keyword_extract(data_asian, 10, 2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9AjA4Hy50tT",
        "outputId": "638830d3-5396-4b4c-b9e6-2a85870f60a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keywords found:\n",
            " ['vaxers', 'antivax']\n",
            "The final terms are: {'vaxers', 'antivax'}\n",
            "\n",
            "Keywords found:\n",
            " ['covidiots', 'contagious', 'coronavirusliar', 'vaccine', 'covid19']\n",
            "The final terms are: {'coronavirusliar', 'covid19'}\n",
            "\n",
            "Keywords found:\n",
            " ['covidiots', 'obv']\n",
            "The final terms are: set()\n",
            "\n",
            "Keywords found:\n",
            " ['covidiots', 'trumpvirus', 'covid', 'vaccine', 'vaccines']\n",
            "The final terms are: {'covid'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['covid']"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_extract(data_vac, 1, 2020)\n",
        "keyword_extract(data_vac, 4, 2020)\n",
        "keyword_extract(data_vac, 7, 2020)\n",
        "keyword_extract(data_vac, 10, 2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b0kEKuU55oI",
        "outputId": "25f61320-5e74-4847-f22e-786fd8b3bec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keywords found:\n",
            " []\n",
            "The final terms are: set()\n",
            "\n",
            "Keywords found:\n",
            " ['pence', 'maskhole']\n",
            "The final terms are: {'maskhole'}\n",
            "\n",
            "Keywords found:\n",
            " ['masks', 'masksdontwork', 'masksoffamerica', 'mask', 'louisianagov', 'independenceday', 'danny', 'dumptrump2020', 'maskhole']\n",
            "The final terms are: {'masksdontwork', 'masksoffamerica', 'louisianagov', 'independenceday', 'dumptrump2020', 'maskhole'}\n",
            "\n",
            "Keywords found:\n",
            " ['schumerresign', 'hole', 'masks', 'mask', 'orifice', 'schumer', 'sunscreen', 'votejoebiden', 'saban', 'maskhole']\n",
            "The final terms are: {'schumerresign', 'votejoebiden', 'maskhole'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['schumerresign', 'votejoebiden', 'maskhole']"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_extract(data_mask, 1, 2020)\n",
        "keyword_extract(data_mask, 4, 2020)\n",
        "keyword_extract(data_mask, 7, 2020)\n",
        "keyword_extract(data_mask, 10, 2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-OyiAFQ5-jW",
        "outputId": "a5521e87-d90a-41d4-f473-0cb656fad416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keywords found:\n",
            " ['cruz', 'qnuts', 'magamorons', 'magaterrorism', 'pence', 'lockthemup', 'magats', 'petition', 'impeached', 'wig', 'fuhrer', 'resign', 'kosher']\n",
            "The final terms are: {'qnuts', 'magamorons', 'magaterrorism', 'lockthemup'}\n",
            "\n",
            "Keywords found:\n",
            " ['stallone']\n",
            "The final terms are: set()\n",
            "\n",
            "Keywords found:\n",
            " ['magamorons', 'threattodemocracy', 'smart']\n",
            "The final terms are: {'magamorons', 'threattodemocracy'}\n",
            "\n",
            "Keywords found:\n",
            " ['lockthemup', 'teabagterrorists', 'loyalists', 'arizonapolitics', 'trumpsters', 'bannon', 'idiots']\n",
            "The final terms are: {'lockthemup', 'arizonapolitics', 'teabagterrorists'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['lockthemup', 'arizonapolitics', 'teabagterrorists']"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_extract(data_us, 1, 2021)\n",
        "keyword_extract(data_us, 4, 2021)\n",
        "keyword_extract(data_us, 7, 2021)\n",
        "keyword_extract(data_us, 10, 2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di9lTApH6Cg8",
        "outputId": "67409a2a-9bf0-4a35-dad4-d582bfcd23a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keywords found:\n",
            " []\n",
            "The final terms are: set()\n",
            "\n",
            "Keywords found:\n",
            " ['nazirussia', 'dmitri', 'ukrainians', 'russiawarcrimes', 'ukrainian', 'nazirussianarmy', 'genocideofukrainians']\n",
            "The final terms are: {'genocideofukrainians', 'russiawarcrimes', 'nazirussia', 'nazirussianarmy'}\n",
            "\n",
            "Keywords found:\n",
            " ['putin', 'russians', 'ukrainewar', 'russiaisaterroriststate', 'ukraineunderatta', 'sanctions', 'ukrainerussiawar', 'russianarmy', 'russianwarcrimes', 'russiaisaterrorisstate', 'russianfascism', 'putinisawarcriminal', 'genocideofukrainians', 'ukrainekrieg']\n",
            "The final terms are: {'ukrainewar', 'russiaisaterroriststate', 'ukraineunderatta', 'putinisawarcriminal', 'ukrainerussiawar', 'russianarmy', 'russianwarcrimes', 'russiaisaterrorisstate', 'russianfascism', 'genocideofukrainians', 'ukrainekrieg'}\n",
            "\n",
            "Keywords found:\n",
            " ['russiaisaterroriststate', 'zaporizhzhia', 'ruzzian', 'russiaisanazistate', 'putinists', 'kakhovka', 'russianlooters', 'ruscist']\n",
            "The final terms are: {'russiaisaterroriststate', 'zaporizhzhia', 'ruzzian', 'russiaisanazistate', 'kakhovka', 'russianlooters', 'ruscist'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['russiaisaterroriststate',\n",
              " 'zaporizhzhia',\n",
              " 'ruzzian',\n",
              " 'russiaisanazistate',\n",
              " 'kakhovka',\n",
              " 'russianlooters',\n",
              " 'ruscist']"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_extract(data_rus, 1, 2022)\n",
        "keyword_extract(data_rus, 4, 2022)\n",
        "keyword_extract(data_rus, 7, 2022)\n",
        "keyword_extract(data_rus, 10, 2022)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
