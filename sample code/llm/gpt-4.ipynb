{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt-4 model\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input your API key here\n",
    "openai.api_key = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Your text here\"\n",
    "prompt = \"\"\"\n",
    "Consider the following comment, and carefully answer the questions in each step to conclude whether it is hate speech or not: \n",
    "comment:\"{text}\"\n",
    "\n",
    "Let's think of it in the following steps:\n",
    "Q1A: Which of the following identities are mentioned in the text?\n",
    "'race', 'nationality', 'age', 'political', 'religion', 'disability', '(anti-)masker', '(anti-)vaxxer'\n",
    "Q1B: Are there any individuals mentioned explicitly by their name?\n",
    "Q2: Are there any derogatory, humiliating, insulting, or disparaging words or phrases specifically mentioned in the text? (Note: Colloquially usage of the words should not be considered)\n",
    "Q3A: If Q2's answer is 'Yes', are those words or phrases directed towards or targeting your selected identities?\n",
    "Q3B: If Q2's answer is 'Yes', are those words or phrases directed towards or targeting individuals?\n",
    "Q4A: If Q3A's answer is 'Yes', do those terms incite hate against the selected identities?\n",
    "Q4B: If Q3B's answer is 'Yes', do those terms incite hate against the individual?\n",
    "Q5A: If Q4A's answer is 'Yes', the comment can be concluded as identity hate speech. Tell me your final conclusion: 'Identity Hate' or 'Non-hate'.\n",
    "Q5B: If Q4B's answer is 'Yes', the comment can be concluded as individual hate speech. Tell me your final conclusion: 'Individual Hate' or 'Non-hate'\n",
    "\"\"\".format(text=text)\n",
    "# print(prompt)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: the following code may need to be modified to fit the updated API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\", \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "sentence  = completion.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with gpt4 model with general prompt\n",
    "def prompt_completion(text):\n",
    "    try:\n",
    "        # we use the user message to mimic the real conversation\n",
    "        prompt = \"\"\"\n",
    "Do you think this comment is hateful?\n",
    "A comment is \"hateful\" if you perceive that it \"expresses hatred toward a targeted group or is intended to be derogatory, to humiliate, or to insult the members of the group.\"\n",
    "comment:\"{text}\"\n",
    "a. Yes b. No\n",
    "\"\"\".format(text=text)   \n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        sentence  = completion.choices[0]['message']['content']\n",
    "        time.sleep(1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        sentence = f\"error: {e}\"\n",
    "        time.sleep(1)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with gpt4 model\n",
    "def prompt_completion_2(text):\n",
    "    try:\n",
    "        # we use the user message to mimic the real conversation\n",
    "        # prompt = f\"Do you think this comment is identity hate speech? comment:\" + text + \"Let's think it by the following steps:\\n1. Which of the following identities are mentioned in the text?\\n 'race', 'nationality', 'age', 'political', 'religion', ‘disability’, '(anti-)masker', '(anti-)vaxxer'\\n2. Are there any derogatory, humiliating, insulting or disparaging words or phrases specifically mentioned in the text?\\n3. If Q2's answer is 'Yes', are those words or phrases directed towards or targeting your selected identities?\\n4. If all the answers are 'Yes', the comment should be a identity hate speech.\\n5. Tell me your final choice: a. Yes b. No\"\n",
    "        prompt = \"\"\"\n",
    "Consider the following comment, and carefully answer the questions in each step to conclude whether it is hate speech or not: \n",
    "comment:\"{text}\"\n",
    "\n",
    "Let's think of it in the following steps:\n",
    "Q1A: Which of the following identities are mentioned in the text?\n",
    "'race', 'nationality', 'age', 'political', 'religion', 'disability', '(anti-)masker', '(anti-)vaxxer'\n",
    "Q1B: Are there any individuals mentioned explicitly by their name?\n",
    "Q2: Are there any derogatory, humiliating, insulting, or disparaging words or phrases specifically mentioned in the text? (Note: Colloquially usage of the words should not be considered)\n",
    "Q3A: If Q2's answer is 'Yes', are those words or phrases directed towards or targeting your selected identities?\n",
    "Q3B: If Q2's answer is 'Yes', are those words or phrases directed towards or targeting individuals?\n",
    "Q4A: If Q3A's answer is 'Yes', do those terms incite hate against the selected identities?\n",
    "Q4B: If Q3B's answer is 'Yes', do those terms incite hate against the individual?\n",
    "Q5A: If Q4A's answer is 'Yes', the comment can be concluded as identity hate speech. Tell me your final conclusion: 'Identity Hate' or 'Non-hate'.\n",
    "Q5B: If Q4B's answer is 'Yes', the comment can be concluded as individual hate speech. Tell me your final conclusion: 'Individual Hate' or 'Non-hate'\n",
    "\"\"\".format(text=text)\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        sentence  = completion.choices[0]['message']['content']\n",
    "        time.sleep(1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        sentence = f\"Error: {e}\"\n",
    "        time.sleep(30)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to modify the following code to fit the CSV data file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded from data/annotation.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "with jsonlines.open(\"{the data}\") as f:\n",
    "    data = [line for line in f]\n",
    "    print(\"data loaded from {}\".format(\"{the data}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path\n",
    "output_path = 'data/gpt4_output.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3990/3990 [18:32:46<00:00, 16.73s/it]   \n"
     ]
    }
   ],
   "source": [
    "# generate output\n",
    "for d in tqdm(data):\n",
    "    d['output'] = prompt_completion_2(d['text'])\n",
    "    with jsonlines.open(output_path, mode='a') as writer:\n",
    "        writer.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun the record which has error\n",
    "i = 0\n",
    "for d in data:\n",
    "    output = d['output']\n",
    "    if output.startswith('Error:'):\n",
    "        text = d['text']\n",
    "        result = prompt_completion_2(text)\n",
    "        d['output'] = result\n",
    "        i += 1\n",
    "        print(\"the {}th record is done:\".format(i))\n",
    "        print(d['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with jsonlines.open(output_path, mode='w') as writer:\n",
    "#         writer.write(data)\n",
    "for d in data:\n",
    "    with jsonlines.open(\"data_gpt4_cot.jsonl\", mode='a') as writer:\n",
    "        writer.write(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
